# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_plots.ipynb.

# %% auto 0
__all__ = ['registry', 'registry_meta', 'stk_plot_defaults', 'n_a', 'priority_weights', 'stk_plot', 'stk_deregister',
           'get_plot_fn', 'get_plot_meta', 'get_all_plots', 'impute_factor_cols', 'calculate_priority',
           'matching_plots', 'estimate_legend_columns_horiz_naive', 'estimate_legend_columns_horiz', 'boxplots',
           'columns', 'stacked_columns', 'diff_columns', 'massplot', 'make_start_end', 'likert_bars', 'kde_1d',
           'density', 'violin', 'cluster_based_reorder', 'matrix', 'lines', 'draws_to_hdis', 'lines_hdi', 'area_smooth',
           'likert_aggregate', 'likert_rad_pol', 'barbell', 'geoplot', 'fd_mangle', 'facet_dist', 'ordered_population',
           'marimekko']

# %% ../nbs/03_plots.ipynb 3
import json, os, math
import itertools as it
from collections import defaultdict

import numpy as np
import pandas as pd
import datetime as dt

from typing import List, Tuple, Dict, Union, Optional

import altair as alt
import scipy as sp
import scipy.stats as sps
from scipy.cluster import hierarchy
from KDEpy import FFTKDE
import arviz as az

from salk_toolkit.utils import *
from salk_toolkit.io import extract_column_meta, read_json

from matplotlib import font_manager
from PIL import ImageFont

# %% ../nbs/03_plots.ipynb 5
registry = {}
registry_meta = {}

# %% ../nbs/03_plots.ipynb 7
stk_plot_defaults = { 'data_format': 'longform' }

# Decorator for registering a plot type with metadata
def stk_plot(plot_name, **r_kwargs):
    
    def decorator(gfunc):
        # In theory, we could do transformations in wrapper
        # In practice, it would only obfuscate already complicated code
        #def wrapper(*args,**kwargs) :
        #    return gfunc(*args,**kwargs)

        # Register the function
        registry[plot_name] = gfunc
        registry_meta[plot_name] = { 'name': plot_name, **stk_plot_defaults, **r_kwargs }
        
        return gfunc
    
    return decorator

def stk_deregister(plot_name):
    del registry[plot_name]
    del registry_meta[plot_name]

def get_plot_fn(plot_name):
    return registry[plot_name]

def get_plot_meta(plot_name):
    return registry_meta[plot_name].copy()

def get_all_plots():
    return sorted(list(registry.keys()))

# %% ../nbs/03_plots.ipynb 8
# Compute the full factor_cols list, including question and res_col as needed
def impute_factor_cols(pp_desc, col_meta):
    plot_meta = get_plot_meta(pp_desc['plot'])
    factor_cols = vod(pp_desc,'factor_cols',[]).copy()

    # Add res_col if we are working with a categorical input (and not converting it to continuous)
    if 'categories' in col_meta[pp_desc['res_col']] and vod(pp_desc,'convert_res')!='continuous' and pp_desc['res_col'] not in factor_cols: 
        factor_cols.insert(0,pp_desc['res_col'])

    # Determine if we have 'question' as a column
    has_q = 'columns' in col_meta[pp_desc['res_col']] # Check if res_col is a group of questions
    n_min_f, _ = vod(plot_meta,'n_facets',(0,0))
    if len(factor_cols)==n_min_f-1 and not has_q: has_q = True # Create 'question' as a dummy dimension to pad out the factors    

    # If we need to, add question as a factor to list
    if has_q and 'question' not in factor_cols:
        if 'categories' in col_meta[pp_desc['res_col']] or vod(plot_meta,'no_question_facet'): factor_cols.append('question') # Put it last for categorical values
        else: factor_cols.insert(0,'question') # And first for continuous values, as it then often represents the "category"

    return factor_cols

# %% ../nbs/03_plots.ipynb 9
# First is weight if not matching, second if match
# This is very much a placeholder right now
n_a = -1000000
priority_weights = {
    'draws': [n_a, 50],
    'nonnegative': [n_a, 50],
    'hidden': [n_a, 0],
    
    'ordered': [n_a, 100],
    'likert': [n_a, 200],
    'required_meta': [n_a, 500],
}

def calculate_priority(plot_meta, match, args, col_meta):
    priority, reasons = vod(plot_meta,'priority',0), []

    args = { **args, 'plot': plot_meta['name']}
    facet_metas = [ col_meta[cn] for cn in impute_factor_cols(args, col_meta)]

    if len(facet_metas)<vod(plot_meta,'n_facets',(0,0))[0]: 
        return n_a, ['n_facets'] # Not enough factors
    else: # Prioritize plots that have the right number of factors
        priority += 10*abs(len(facet_metas)-vod(plot_meta,'n_facets',(0,0))[1])

    for k in ['draws','nonnegative','hidden']:
        if vod(plot_meta,k):
            val = priority_weights[k][1 if vod(match,k) else 0]
            if val < 0: reasons.append(k)
            priority += val

    for i, d in enumerate(vod(plot_meta,'requires',[])):
        md = facet_metas[i]
        for k, v in d.items():
            if v!='pass': val = priority_weights[k][1 if vod(md,k)==v else 0]
            else: val = priority_weights['required_meta'][1 if k in md else 0] # Use these weights for things plots require from metadata
            
            if k == 'ordered' and vod(md,'continuous'): val = priority_weights[k][1] # Continuous is turned into ordered categoricals for facets
            if val < 0: reasons.append(k)
            priority += val
                                     
    return priority, reasons


# Get a list of plot types matching required spec
def matching_plots(args, df, data_meta, details=False, list_hidden=False):
    col_meta = extract_column_meta(data_meta)
    
    rc = args['res_col']
    rcm = col_meta[rc]


    # Determine if values are non-negative
    nonneg = ('categories' in col_meta[rc]) or df[ rcm['columns'] if 'columns' in rcm else rc ].min(axis=None)>=0
    if vod(args,'convert_res')=='continuous' and ('categories' in col_meta[rc]):
        nonneg = min(vod(col_meta[rc],'num_values',[0]))>=0

    match = {
        'draws': ('draw' in df.columns),
        'nonnegative': nonneg,
        'hidden': list_hidden
    }
    
    res = [ ( pn, *calculate_priority(get_plot_meta(pn),match,args,col_meta)) for pn in registry.keys() ]
    
    if details: return { n: (p, i) for (n, p, i) in res } # Return dict with priorities and failure reasons
    else: return [ n for (n,p,i) in sorted(res,key=lambda t: t[1], reverse=True) if p >= 0 ] # Return list of possibilities in decreasing order of fit

# %% ../nbs/03_plots.ipynb 15
# Find a sensible approximation to the font used in vega/altair
font = font_manager.FontProperties(family='sans-serif', weight='regular')
font_file = font_manager.findfont(font)
legend_font = ImageFont.truetype(font_file,10)

# %% ../nbs/03_plots.ipynb 16
# Legends are not wrapped, nor is there a good way of doing accurately it in vega/altair
# This attempts to estimate a reasonable value for columns which induces wrapping
def estimate_legend_columns_horiz_naive(cats, width):
    max_str_len = max(map(len,cats))
    n_cols = max(1,width//(15+5*max_str_len))
    # distribute them roughly equally to avoid last row being awkwardly shorter
    n_rows = int(math.ceil(len(cats)/n_cols))
    return int(math.ceil(len(cats)/n_rows))

# More sophisticated version that looks at lengths of individual strings across multiple rows
# ToDo: it should max over each column separately not just look at max(sum(row)). This is close enough though.
def estimate_legend_columns_horiz(cats, width):
    max_cols, restart = len(cats), True
    lens = list(map(lambda s: 15+legend_font.getlength(s),cats))
    while restart:
        restart, rl, cc = False, 0, 0
        for l in lens:
            if cc >= max_cols: # Start a new row
                rl, cc = l, 1
            elif rl + l > width: # Exceed width - restart
                max_cols = cc
                # Start from beginning every thime columns number changes
                # This is because what ends up in second+ rows depends on length of first
                restart = True
            else: # Just append to existing row
                rl += l
                cc += 1
                
    # For very long labels just accept we can't do anything
    max_cols = max(max_cols,1)

    # distribute them roughly equally to avoid last row being awkwardly shorter
    n_rows = int(math.ceil(len(cats)/max_cols))
    return int(math.ceil(len(cats)/n_rows))

# %% ../nbs/03_plots.ipynb 20
@stk_plot('boxplots', data_format='longform', draws=True, n_facets=(1,2), priority=50)
def boxplots(data, value_col='value', facets=[], val_format='%', width=800, tooltip=[]):
    f0, f1 = facets[0], facets[1] if len(facets)>1 else None

    if val_format[-1] == '%': # Boxplots being a compound plot, this workaround is needed for axis & tooltips to be proper
        data[value_col]*=100
        val_format = val_format[:-1]+'f'
    
    shared = {
        'y': alt.Y(f'{f0["col"]}:N', title=None, sort=f0['order']),

        **({
            'color': alt.Color(f'{f0["col"]}:N', scale=f0['colors'], legend=None)    
            } if not f1 else {
                'yOffset':alt.YOffset(f'{f1["col"]}:N', title=None, sort=f1['order']), 
                'color': alt.Color(f'{f1["col"]}:N', scale=f1['colors'], 
                                   legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f1['order'],width)))
            })
    }
    
    base = alt.Chart(round(data, 2))
    
    # This plot is here because boxplot does not draw if variance is very low, so this is the backup
    tick_plot = base.mark_tick(thickness=3).encode(
        x=alt.X(f'mean({value_col}):Q'),
        tooltip=[alt.Tooltip(f'mean({value_col}):Q')] + tooltip[1:],
        **shared
    )
    
    box_plot = base.mark_boxplot(
        clip=True,
        #extent='min-max',
        outliers=False
    ).encode(
        x=alt.X(
            f'{value_col}:Q',
            title=value_col,
            axis=alt.Axis(format=val_format)
            ),
        tooltip=tooltip[1:],
        **shared,
    )
    return tick_plot + box_plot

# %% ../nbs/03_plots.ipynb 22
@stk_plot('columns', data_format='longform', draws=False, n_facets=(1,2))
def columns(data, value_col='value', facets=[], val_format='%', width=800, tooltip=[]):
    f0, f1 = facets[0], facets[1] if len(facets)>1 else None
    plot = alt.Chart(round(data, 3), width = 'container' \
    ).mark_bar().encode(
        x=alt.X(
            f'{value_col}:Q',
            title=value_col,
            axis=alt.Axis(format=val_format),
        ),
        y=alt.Y(f'{f0["col"]}:N', title=None, sort=f0["order"]),
        tooltip = tooltip,
        **({
                'color': alt.Color(f'{f0["col"]}:N', scale=f0["colors"], legend=None)    
            } if not f1 else {
                'yOffset':alt.YOffset(f'{f1["col"]}:N', title=None, sort=f1["order"]),
                'color': alt.Color(f'{f1["col"]}:N', scale=f1["colors"],
                                    legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f1["order"],width)))
            }),
    )
    return plot

# %% ../nbs/03_plots.ipynb 25
@stk_plot('stacked_columns', data_format='longform', draws=False, nonnegative=True, n_facets=(2,2), agg_fn='sum', args={'normalized':'bool'})
def stacked_columns(data, value_col='value', facets=[], n_datapoints=1, val_format='%', width=800, normalized=False, tooltip=[]):
    f0, f1 = facets[0], facets[1]
    
    data[value_col] = data[value_col]/n_datapoints
    
    ldict = dict(zip(f1["order"], range(len(f1["order"]))))
    data['f_order'] = data[f1["col"]].astype('object').replace(ldict).astype('int')
    
    plot = alt.Chart(round(data, 3), width = 'container' \
    ).mark_bar().encode(
        x=alt.X(
            f'{value_col}:Q',
            title=value_col,
            axis=alt.Axis(format=val_format),
            **({'stack':'normalize'} if normalized else {})
            #scale=alt.Scale(domain=[0,30]) #see lõikab mõnedes jaotustes parema ääre ära
        ),
        y=alt.Y(f'{f0["col"]}:N', title=None, sort=f0["order"]),
        tooltip = tooltip,
        **({
                'color': alt.Color(f'{f0["col"]}:N', scale=f0["colors"], legend=None)    
            } if len(facets)<=1 else {
                'order': alt.Order('f_order:O'),
                'color': alt.Color(f'{f1["col"]}:N', scale=f1["colors"],
                                    legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f1["order"],width)))
            }),
    )
    return plot

# %% ../nbs/03_plots.ipynb 27
@stk_plot('diff_columns', data_format='longform', draws=False, n_facets=(2,2), args={'sort_descending':'bool'})
def diff_columns(data, value_col='value', facets=[], val_format='%', sort_descending=False, tooltip=[]):
    f0, f1 = facets[0], facets[1]
    
    ind_cols = list(set(data.columns)-{value_col,f1["col"]})
    factors = data[f1["col"]].unique() # use unique instead of categories to allow filters to select the two that remain
    
    idf = data.set_index(ind_cols)
    diff = (idf[idf[f1["col"]]==factors[1]][value_col]-idf[idf[f1["col"]]==factors[0]][value_col]).reset_index()
    
    if sort_descending: f0["order"] = list(diff.sort_values(value_col,ascending=False)[f0["col"]])
    
    plot = alt.Chart(round(diff, 3), width = 'container' \
    ).mark_bar().encode(
        y=alt.Y(f'{f0["col"]}:N', title=None, sort=f0["order"]),
        x=alt.X(
            f'{value_col}:Q',
            title=f"{factors[1]} - {factors[0]}",
            axis=alt.Axis(format=val_format, title=f"{factors[0]} <> {factors[1]}"),
            #scale=alt.Scale(domain=[0,30]) #see lõikab mõnedes jaotustes parema ääre ära
            ),
        
        tooltip=[
            alt.Tooltip(f'{f0["col"]}:N'),
            alt.Tooltip(f'{value_col}:Q',format=val_format, title=f'{value_col} difference')
            ],
        color=alt.Color(f'{f0["col"]}:N', scale=f0["colors"], legend=None)    
    )
    return plot

# %% ../nbs/03_plots.ipynb 29
# The idea was to also visualize the size of each cluster. Currently not very useful, may need to be rethought

@stk_plot('massplot', data_format='longform', draws=False, group_sizes=True, n_facets=(1,2), hidden=True)
def massplot(data, value_col='value', facets=[], n_datapoints=1, val_format='%', width=800, tooltip=[]):
    f0, f1 = facets[0], facets[1] if len(facets)>1 else None

    data['group_size']=(data['group_size']/n_datapoints)#.round(2)

    plot = alt.Chart(round(data, 3), width = 'container' \
    ).mark_circle().encode(
        y=alt.Y(f'{f0["col"]}:N', title=None, sort=f0["order"]),
        x=alt.X(
            f'{value_col}:Q',
            title=value_col,
            axis=alt.Axis(format=val_format),
            #scale=alt.Scale(domain=[0,30]) #see lõikab mõnedes jaotustes parema ääre ära
            ),
        size=alt.Size('group_size:Q', legend=None, scale=alt.Scale(range=[100, 500])),
        opacity=alt.value(1.0),
        stroke=alt.value('#777'),
        tooltip = tooltip + [ alt.Tooltip('group_size:N',format='.1%',title='Group size') ],
        #tooltip=[
        #    'response:N',
            #alt.Tooltip('mean(support):Q',format='.1%')
        #    ],
        **({
                'color': alt.Color(f'{f0["col"]}:N', scale=f0["colors"], legend=None)    
            } if not f1 else {
                'yOffset':alt.YOffset(f'{f1["col"]}:N', title=None, sort=f1["order"]), 
                'color': alt.Color(f'{f1["col"]}:N', scale=f1["colors"],
                                legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f1["order"],width)))
            }),
    )
    return plot

# %% ../nbs/03_plots.ipynb 31
# Make the likert bar pieces
def make_start_end(x,value_col,cat_col,cat_order):
    #print("######################")
    #print(x)
    if len(x) != len(cat_order):
        # Fill in missing rows with value zero so they would just be skipped
        x = pd.merge(pd.DataFrame({cat_col:cat_order}),x,on=cat_col,how='left').fillna({value_col:0})
    mid = len(x)//2
        
    if len(x)%2==1: # odd:
        scale_start=1.0
        x_mid = x.iloc[[mid],:]
        x_mid.loc[:,['start','end']] = -scale_start
        x_mid.loc[:,'end'] = -scale_start+x_mid[value_col]
        nonmid = [ i for i in range(len(x)) if i!=mid ]
        x_mid = [x_mid]
    else: # even - no separate mid
        nonmid = np.arange(len(x))
        x_mid = []
    
    x_other = x.iloc[nonmid,:].copy()
    x_other.loc[:,'end'] = x_other[value_col].cumsum() - x_other[:mid][value_col].sum()
    x_other.loc[:,'start'] = (x_other[value_col][::-1].cumsum()[::-1] - x_other[mid:][value_col].sum())*-1
    res = pd.concat([x_other] + x_mid).dropna() # drop any na rows added in the filling in step
    #print(res)
    return res

@stk_plot('likert_bars', data_format='longform', draws=False, requires=[{'likert':True}], n_facets=(2,3), priority=50)
def likert_bars(data, value_col='value', facets=[],  tooltip=[], outer_factors=[]):
    # First facet is likert, second is labeled question, third is offset. Second is better for question which usually goes last, hence reorder
    if len(facets)>=3: f0, f1, f2 = facets[0], facets[2], facets[1]
    else: f0, f1, f2 = facets[0], facets[1], None
    gb_cols = outer_factors+[f["col"] for f in facets[1:]] # There can be other extra cols (like labels) that should be ignored
    options_cols = list(data[f0["col"]].dtype.categories) # Get likert scale names
    bar_data = data.groupby(gb_cols, group_keys=False, observed=False)[data.columns].apply(make_start_end, value_col=value_col,cat_col=f0["col"],cat_order=f0["order"],include_groups=False)
    
    plot = alt.Chart(bar_data).mark_bar() \
        .encode(
            x=alt.X('start:Q', axis=alt.Axis(title=None, format = '%')),
            x2=alt.X2('end:Q'),
            y=alt.Y(f'{f1["col"]}:N', axis=alt.Axis(title=None, offset=5, ticks=False, minExtent=60, domain=False), sort=f1["order"]),
            tooltip=tooltip,
            color=alt.Color(
                f'{f0["col"]}:N',
                legend=alt.Legend(
                    title='Response',
                    orient='bottom',
                    ),
                scale=f0["colors"],
            ),
            **({ 'yOffset':alt.YOffset(f'{f2["col"]}:N', title=None, sort=f2["order"]),
                 #'strokeWidth': alt.value(3)
               } if f2 else {})
        )
    return plot

# %% ../nbs/03_plots.ipynb 33
# Calculate KDE ourselves using a fast libary. This gets around having to do sampling which is unstable
def kde_1d(vc, value_col, ls, scale=False):
    y =  FFTKDE(kernel='gaussian').fit(vc.to_numpy()).evaluate(ls)
    if scale: y*=len(vc)
    return pd.DataFrame({'density': y, value_col: ls})

@stk_plot('density', data_format='raw', factor_columns=3, aspect_ratio=(1.0/1.0), n_facets=(0,1), args={'stacked':'bool'}, no_question_facet=True)
def density(data, value_col='value', facets=[], tooltip=[], outer_factors=[], stacked=False, width=800):
    f0 = facets[0] if len(facets)>0 else None
    gb_cols = [ c for c in outer_factors+[f['col'] for f in facets] if c is not None ] # There can be other extra cols (like labels) that should be ignored
    
    ls = np.linspace(data[value_col].min()-1e-10,data[value_col].max()+1e-10,200)
    ndata = gb_in_apply(data,gb_cols,cols=[value_col],fn=kde_1d,value_col=value_col,ls=ls,scale=stacked).reset_index()

    if stacked:
        
        if f0:
            ldict = dict(zip(f0["order"], reversed(range(len(f0["order"])))))
            ndata.loc[:,'order'] = ndata[f0["col"]].astype('object').replace(ldict).astype('int')
        
        ndata['density'] /= len(data)
        plot=alt.Chart(ndata).mark_area(interpolate='natural').encode(
                x=alt.X(f"{value_col}:Q"),
                y=alt.Y('density:Q',axis=alt.Axis(title=None, format = '%'),stack='zero'),
                tooltip = tooltip[1:],
                **({'color': alt.Color(f'{f0["col"]}:N', scale=f0["colors"], legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f0["order"],width))), 'order': alt.Order('order:O')} if f0 else {})
            )
    else:
        plot = alt.Chart(
                ndata
            ).mark_line().encode(
                x=alt.X(f"{value_col}:Q"),
                y=alt.Y('density:Q',axis=alt.Axis(title=None, format = '%')),
                tooltip = tooltip[1:],
                **({'color': alt.Color(f'{f0["col"]}:N', scale=f0["colors"], legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f0["order"],width)))} if f0 else {})
            )
    return plot

# %% ../nbs/03_plots.ipynb 35
@stk_plot('violin', data_format='raw', n_facets=(1,2), as_is=True)
def violin(data, value_col='value', facets=[], tooltip=[], outer_factors=[],width=800):
    f0, f1 = facets[0], facets[1] if len(facets)>1 else None
    gb_cols = outer_factors + [ f['col'] for f in facets ] # There can be other extra cols (like labels) that should be ignored
    
    ls = np.linspace(data[value_col].min()-1e-10,data[value_col].max()+1e-10,200)
    ndata = gb_in_apply(data,gb_cols,cols=[value_col],fn=kde_1d,value_col=value_col,ls=ls,scale=True).reset_index()
    
    if f1:
        ldict = dict(zip(f1["order"], reversed(range(len(f1["order"])))))
        ndata.loc[:,'order'] = ndata[f1["col"]].astype('object').replace(ldict).astype('int')

    ndata['density'] /= len(data)
    plot=alt.Chart(ndata).mark_area(interpolate='natural').encode(
            x=alt.X(f"{value_col}:Q"),
            y=alt.Y('density:Q',axis=alt.Axis(title=None, labels=False, values=[0], grid=False),stack='center'),
            row=alt.Row(f'{f0["col"]}:N',header=alt.Header(orient='top',title=None),spacing=5,sort=f0["order"]),
            tooltip = tooltip[1:],
            #color=alt.Color(f'{question_col}:N'),
            **({'color': alt.Color(f'{f1["col"]}:N', scale=f1["colors"], legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f1["order"],width))), 'order': alt.Order('order:O')} if f1 else 
               {'color': alt.Color(f'{f0["col"]}:N', scale=f0["colors"], legend=None)})
        ).properties(width=width,height=70)

    return plot

# %% ../nbs/03_plots.ipynb 37
# Cluster-based reordering
def cluster_based_reorder(X):
    pd = sp.spatial.distance.pdist(X)#,metric='cosine')
    return hierarchy.leaves_list(hierarchy.optimal_leaf_ordering(hierarchy.ward(pd), pd))

@stk_plot('matrix', data_format='longform', aspect_ratio=(1/0.8), n_facets=(2,2), args={'reorder':'bool'})
def matrix(data, value_col='value', facets=[], val_format='%', reorder=False, row_normalize=False, tooltip=[]):
    f0, f1 = facets[0], facets[1]
    
    fcols = [c for c in data.columns if c not in [value_col,f0["col"]]]
    if len(fcols)==1 and reorder: # Reordering only works if no external facets
        X = data.pivot(columns=f1["col"],index=f0["col"]).to_numpy()
        f0["order"] = np.array(f0["order"])[cluster_based_reorder(X)]
        f1["order"] = np.array(f1["order"])[cluster_based_reorder(X.T)]
    
    # Find max absolute value to keep color scale symmetric
    dmax = max(-data[value_col].min(),data[value_col].max())
    
    # Draw colored boxes
    base = alt.Chart(data).mark_rect().encode(
            x=alt.X(f'{f1["col"]}:N', title=None, sort=f1["order"]),
            y=alt.Y(f'{f0["col"]}:N', title=None, sort=f0["order"]),
            color=alt.Color(f'{value_col}:Q', scale=alt.Scale(scheme='redyellowgreen', domainMid=0, domainMin=-dmax, domainMax=dmax),
                legend=alt.Legend(title=None)),
            tooltip=tooltip,
        )
    
    # Add in numerical values
    text = base.mark_text().encode(
        text=alt.Text(f'{value_col}:Q', format=val_format),
        color=alt.condition(
            alt.datum[f'{value_col}:Q']**2 > 1.5,
            alt.value('white'),
            alt.value('black')
        ),
        tooltip=tooltip
    )
    
    return base+text

# %% ../nbs/03_plots.ipynb 41
@stk_plot('lines',data_format='longform', draws=False, requires=[{},{'ordered':True}], n_facets=(2,2), args={'smooth':'bool'})
def lines(data, value_col='value', facets=[], smooth=False, width=800, tooltip=[], val_format='.2f',):
    f0, f1 = facets[0], facets[1]
    if smooth:
        smoothing = 'basis'
        points = 'transparent'
    else:
        smoothing = 'natural'
        points = True
    plot = alt.Chart(data).mark_line(point=points, interpolate=smoothing).encode(
        alt.X(f'{f1["col"]}:N', title=None, sort=f1["order"]),
        alt.Y(f'{value_col}:Q', title=None, axis=alt.Axis(format=val_format)),
        tooltip=tooltip,
        color=alt.Color(f'{f0["col"]}:N', scale=f0["colors"], sort=f0["order"],
                        legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f0["order"],width)))
    )
    return plot

# %% ../nbs/03_plots.ipynb 43
def draws_to_hdis(data,vc,hdi_vals):
    gbc = [ c for c in data.columns if c not in [vc,'draw'] ]
    ldfs = []
    for hdiv in hdi_vals:
        ldf_v = data.groupby(gbc,observed=False)[vc].apply(lambda s: pd.Series(list(az.hdi(s.to_numpy(),hdi_prob=hdiv)),index=['lo','hi'])).reset_index()
        ldf_v['hdi']=hdiv
        ldfs.append(ldf_v)
    ldf = pd.concat(ldfs).reset_index(drop=True)
    df = ldf.pivot(index=gbc+['hdi'], columns=ldf.columns[-3],values=vc).reset_index()
    return df

@stk_plot('lines_hdi',data_format='longform', draws=True, requires=[{},{'ordered':True}], n_facets=(2,2), args={'hdi1':'float','hdi2':'float'})
def lines_hdi(data, value_col='value', facets=[], width=800, tooltip=[], val_format='.2f', hdi1=0.94, hdi2=0.5):
    f0, f1 = facets[0], facets[1]
    
    hdf = draws_to_hdis(data,value_col,[hdi1,hdi2])
    # Draw them in reverse order so the things that are first (i.e. most important) are drawn last (i.e. on top of others)
    # Also draw wider hdi before the narrower
    hdf.sort_values([f0["col"],'hdi'],ascending=[False,False],inplace=True)

    plot = alt.Chart(hdf).mark_area(interpolate='basis').encode(
        alt.X(f'{f1["col"]}:O', title=None, sort=f1["order"]),
        y=alt.Y('lo:Q',
            axis=alt.Axis(format=val_format),
            title=value_col
            ),
        y2=alt.Y2('hi:Q'),
        color=alt.Color(
            f'{f0["col"]}:N',
            sort=f0["order"],
            scale=f0["colors"]
            ),
        opacity=alt.Opacity('hdi:N',legend=None,scale=to_alt_scale({0.5:0.75,0.94:0.25})),
        tooltip=[
            alt.Tooltip('hdi:N', title='HDI', format='.0%'),
            alt.Tooltip('lo:Q', title='HDI lower', format=val_format),
            alt.Tooltip('hi:Q', title='HDI upper', format=val_format),] + tooltip[1:]
        )
    return plot

# %% ../nbs/03_plots.ipynb 45
@stk_plot('area_smooth',data_format='longform', draws=False, nonnegative=True, requires=[{},{'ordered':True}], n_facets=(2,2))
def area_smooth(data, value_col='value', facets=[], width=800, tooltip=[]):
    f0, f1 = facets[0], facets[1]
    ldict = dict(zip(f0["order"], range(len(f0["order"]))))
    data.loc[:,'order'] = data[f0["col"]].astype('object').replace(ldict).astype('int')
    plot=alt.Chart(data
        ).mark_area(interpolate='natural').encode(
            x=alt.X(f'{f1["col"]}:O', title=None, sort=f1["order"]),
            y=alt.Y(f'{value_col}:Q', title=None, stack='normalize',
                 scale=alt.Scale(domain=[0, 1]), axis=alt.Axis(format='%')
                 ),
            order=alt.Order('order:O'),
            color=alt.Color(f'{f0["col"]}:N',
                legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f0["order"],width)),
                sort=f0["order"], scale=f0["colors"]
                ),
            tooltip=tooltip
        )
    return plot

# %% ../nbs/03_plots.ipynb 47
def likert_aggregate(x, cat_col, cat_order, value_col):
    
    cc, vc = x[cat_col], x[value_col]
    cats = cat_order
    
    mid, odd = len(cats)//2, len(cats)%2
    
    nonmid_sum = vc[cc !=  cats[mid]].sum() if odd else vc.sum()
    
    #print(len(x),x.columns,x.head())
    pol = ( np.minimum(
                vc[cc.isin(cats[:mid])].sum(),
                vc[cc.isin(cats[mid+odd:])].sum()
            ) / nonmid_sum )

    rad = ( vc[cc.isin([cats[0],cats[-1]])].sum() /
            nonmid_sum )

    rel = 1.0-nonmid_sum/vc.sum()
    
    return pd.Series({ 'polarisation': pol, 'radicalisation':rad, 'relevance':rel})

@stk_plot('likert_rad_pol',data_format='longform', requires=[{'likert':True}], args={'normalized':'bool'}, n_facets=(1,2))
def likert_rad_pol(data, value_col='value', facets=[], normalized=True, width=800, outer_factors=[], tooltip=[]):
    f0, f1 = facets[0], facets[1] if len(facets)>1 else None
    #gb_cols = list(set(data.columns)-{ f0["col"], value_col }) # Assume all other cols still in data will be used for factoring
    gb_cols = outer_factors + [f['col'] for f in facets[1:]] # There can be other extra cols (like labels) that should be ignored
    
    options_cols = list(data[f0["col"]].dtype.categories) # Get likert scale names
    likert_indices = data.groupby(gb_cols, group_keys=False, observed=False).apply(likert_aggregate,cat_col=f0["col"],cat_order=f0["order"],value_col=value_col,include_groups=False).reset_index()
    
    if normalized: likert_indices.loc[:,['polarisation','radicalisation']] = likert_indices[['polarisation','radicalisation']].apply(sps.zscore)
    
    plot = alt.Chart(likert_indices).mark_point().encode(
        x=alt.X('polarisation:Q'),
        y=alt.Y('radicalisation:Q'),
        size=alt.Size('relevance:Q', legend=None, scale=alt.Scale(range=[100, 500])),
        opacity=alt.value(1.0),
        #stroke=alt.value('#777'),
        tooltip=[
            alt.Tooltip('radicalisation:Q', format='.2'),
            alt.Tooltip('polarisation:Q', format='.2'),
            alt.Tooltip('relevance:Q', format='.2')
        ] + tooltip[2:],
        **({'color': alt.Color(f'{f1["col"]}:N', scale=f1["colors"], 
                               legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f1["order"],width)))
            } if f1 else {})
        )
    return plot

# %% ../nbs/03_plots.ipynb 49
@stk_plot('barbell', data_format='longform', draws=False, n_facets=(2,2))
def barbell(data, value_col='value', facets=[], n_datapoints=1, val_format='%', width=800, tooltip=[]):
    f0, f1 = facets[0], facets[1]
    
    chart_base = alt.Chart(data).encode(
        alt.X(f'{value_col}:Q', title=None, axis=alt.Axis(format=val_format)),
        alt.Y(f'{f0["col"]}:N', title=None, sort=f0["order"]),
        tooltip=tooltip
    )

    chart = chart_base.mark_line(color='lightgrey', size=1, opacity=1.0).encode(
        detail=f'{f0["col"]}:N'
    )
    selection = alt.selection_point(fields=[f1["col"]], bind='legend')

    chart += chart_base.mark_point(
        size=50,
        opacity=1,
        filled=True
    ).encode(
        color=alt.Color(f'{f1["col"]}:N',
            #legend=alt.Legend(orient='right', title=None),
            legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f1["order"],width)),
            scale=f1["colors"],
            sort=f1["order"]
        ),
        opacity=alt.condition(selection, alt.value(1), alt.value(0.2)),
    ).add_params(
        selection
    )#.interactive()
    
    return chart

# %% ../nbs/03_plots.ipynb 52
@stk_plot('geoplot', data_format='longform', n_facets=(1,1), requires=[{'topo_feature':'pass'}], aspect_ratio=(4.0/3.0), no_question_facet=True)
def geoplot(data, topo_feature, value_col='value', facets=[], val_format='.2f',tooltip=[]):
    f0 = facets[0]

    tjson_url, tjson_meta, tjson_col = topo_feature
    source = alt.topo_feature(tjson_url, tjson_meta)

    plot = alt.Chart(source).mark_geoshape(stroke='white', strokeWidth=0.1).transform_lookup(
        lookup = f"properties.{tjson_col}",
        from_ = alt.LookupData(
            data=data,
            key=f0["col"],
            fields=list(data.columns)
        ),
    ).encode(
        tooltip=tooltip, #[alt.Tooltip(f'properties.{tjson_col}:N', title=f1["col"]),
                #alt.Tooltip(f'{value_col}:Q', title=value_col, format=val_format)],
        color=alt.Color(
            f'{value_col}:Q',
            scale=alt.Scale(scheme="reds"), # To use color scale, consider switching to opacity for value
            legend=alt.Legend(format=val_format, title=None, orient='top-left',gradientThickness=6),
        )
    ).project('mercator')
    return plot

# %% ../nbs/03_plots.ipynb 54
# Assuming ns is ordered by unique row values, find the split points
def split_ordered(cvs):
    if len(cvs.shape)==1: cvs = cvs[:,None]
    unique_idxs = np.empty(len(cvs), dtype=np.bool_)
    unique_idxs[:1] = False
    unique_idxs[1:] = np.any(cvs[:-1, :] != cvs[1:, :], axis=-1)
    return np.arange(len(unique_idxs))[unique_idxs]

# Split a series of weights into groups of roughly equal sum
# This algorithm is greedy and does not split values but it is fast and should be good enough for most uses
def split_even_weight(ws, n):
    cws = np.cumsum(ws)
    cws = (cws/(cws[-1]/n)).astype('int')
    return (split_ordered(cws)+1)[:-1]

# %% ../nbs/03_plots.ipynb 56
def fd_mangle(vc, value_col, factor_col, n_points=10): 
    
    vc = vc.sort_values(value_col)
    
    ws = np.ones(len(vc))
    splits = split_even_weight(ws, n_points)
    
    ccodes, cats = vc[factor_col].factorize()
    
    ofreqs = np.stack([ np.bincount(g, weights=gw, minlength=len(cats))/gw.sum()
                        for g,gw in zip(np.split(ccodes,splits),np.split(ws,splits)) ],axis=0)
    
    df = pd.DataFrame(ofreqs, columns=cats)
    df['percentile'] = np.linspace(0,1,n_points)
    return df.melt(id_vars='percentile',value_vars=cats,var_name=factor_col,value_name='density')

@stk_plot('facet_dist', data_format='raw', factor_columns=3,aspect_ratio=(1.0/1.0), n_facets=(1,1), no_question_facet=True)
def facet_dist(data, value_col='value',facets=[], tooltip=[], outer_factors=[]):
    f0 = facets[0]
    gb_cols = [ c for c in outer_factors if c is not None ] # There can be other extra cols (like labels) that should be ignored
    ndata = gb_in_apply(data,gb_cols,cols=[value_col,f0["col"]],fn=fd_mangle,value_col=value_col,factor_col=f0["col"]).reset_index()
    plot=alt.Chart(ndata).mark_area(interpolate='natural').encode(
            x=alt.X(f"percentile:Q",axis=alt.Axis(format='%')),
            y=alt.Y('density:Q',axis=alt.Axis(title=None, format = '%'),stack='normalize'),
            tooltip = tooltip[1:],
            color=alt.Color(f'{f0["col"]}:N', scale=f0["colors"], legend=alt.Legend(orient='top')),
            #order=alt.Order('order:O')
    )

    return plot

# %% ../nbs/03_plots.ipynb 58
# Vectorized multinomial sampling. Should be slightly faster
def vectorized_mn(prob_matrix):
    s = prob_matrix.cumsum(axis=1)
    s = s/s[:,-1][:,None]
    r = np.random.rand(prob_matrix.shape[0])[:,None]
    return (s < r).sum(axis=1)

def linevals(vals, value_col, n_points, dim, cats, ccodes=None, ocols=None, boost_signal=True,gc=False, weights=None):
    ws = weights if weights is not None else np.ones(len(vals))
    
    order = np.lexsort((vals,ccodes)) if dim and gc else np.argsort(vals)
    splits = split_even_weight(ws[order], n_points)
    aer = np.array([ g.mean() for g in np.split(vals[order],splits) ])
    pdf = pd.DataFrame(aer, columns=[value_col])
    
    if dim:
        # Find the frequency of each category in ccodes
        osignal = np.stack([ np.bincount(g, weights=gw, minlength=len(cats))/gw.sum()
                            for g,gw in zip(np.split(ccodes[order],splits),np.split(ws[order],splits)) ],axis=0)
        
        ref_p = osignal.mean(axis=0)+1e-10
        np.random.seed(0) # So they don't change every re-render

        signal = osignal + 1e-10 # So even if values are zero, log and vectorized_mn would work
        if boost_signal: # Boost with K-L, leaving only categories that grew in probability boosted by how much they did
            klv = signal*(np.log(signal/ref_p[None,:]))
            signal = np.maximum(1e-10,klv)
            pdf['kld'] = np.sum(klv,axis=1)

        #pdf[dim] = cats[signal.apply(lambda r: np.random.multinomial(1,r/r.sum()).argmax() if r.sum()>0.0 else 0,axis=1)]
        cat_inds = vectorized_mn(signal)
        pdf[dim] = np.array(cats)[cat_inds]
        pdf['probability'] = osignal[np.arange(len(cat_inds)),cat_inds]

        #pdf[dim] = pdf[cats].idxmax(axis=1)
        #pdf['weight'] = np.minimum(pdf[cats].max(axis=1),pdf['matches'])

    pdf['pos'] = np.arange(0,1,1.0/len(pdf))
    
    if ocols is not None:
        for iv in ocols.index:
            pdf[iv] = ocols[iv]

    return pdf

# %% ../nbs/03_plots.ipynb 59
@stk_plot('ordered_population', data_format='raw', factor_columns=3, aspect_ratio=(1.0/1.0), plot_args={'group_categories':'bool'}, n_facets=(0,1), no_question_facet=True)
def ordered_population(data, value_col='value', facets=[], tooltip=[], outer_factors=[], group_categories=False):
    f0 = facets[0] if len(facets)>0 else None
    
    n_points, maxn = 200, 1000000
    
     # TODO: use weight if available. linevals is ready for it, just needs to be fed in. 
    
    # Sample down to maxn points if exceeding that
    if len(data)>maxn: data = data.sample(maxn,replace=False)
    
    data = data.sort_values(outer_factors)
    vals = data[value_col].to_numpy()

    if len(facets)>=1:
        fcol = f0["col"]
        cat_idx, cats = pd.factorize(data[f0["col"]])
        cats = list(cats)
    else:
        fcol = None
        cat_idx, cats = None, []
        
    if outer_factors:
        
        # This is optimized to not use pandas.groupby as it makes it about 2x faster - which is 2+ seconds with big datasets
        
        # Assume data is sorted by outer_factors, split vals into groups by them
        ofids = np.stack([ data[f].cat.codes.values for f in outer_factors ],axis=1)
        splits = split_ordered(ofids)        
        groups = np.split(vals,splits)
        cgroups = np.split(cat_idx,splits) if len(facets)>=1 else groups
        
        # Perform the equivalent of groupby
        ocols = data.iloc[[0]+list(splits)][outer_factors]
        tdf = pd.concat([linevals(g,value_col=value_col,dim=fcol, ccodes=gc, cats=cats, n_points=n_points,ocols=ocols.iloc[i,:],gc=group_categories) 
                         for i,(g,gc) in enumerate(zip(groups,cgroups))])

        #tdf = data.groupby(outer_factors,observed=True).apply(linevals,value_col=value_col,dim=fcol,cats=cats,n_points=n_points,gc=group_categories,include_groups=False).reset_index()
    else:
        tdf = linevals(vals,value_col=value_col,dim=fcol,ccodes=cat_idx,cats=cats,n_points=n_points, gc=group_categories)
        #tdf = linevals(data,value_col=value_col,cats=cats,dim=fcol,n_points=n_points,gc=group_categories)
        
    #if boost_signal:
    #    tdf['matches'] = np.minimum(tdf['matches'],tdf['kld']/tdf['kld'].quantile(0.75))

    base = alt.Chart(tdf).encode(
        x=alt.X('pos:Q',
            title="",
            axis=alt.Axis(
                labels=False,
                ticks=False,
                #grid=False
            )
        )
    )
    #selection = alt.selection_multi(fields=[dim], bind='legend')
    line = base.mark_circle(size=10).encode(
        y=alt.Y(f"{value_col}:Q",impute={'value':None}, title='', axis=alt.Axis(grid=True)),
        #opacity=alt.condition(selection, alt.Opacity("matches:Q",scale=None), alt.value(0.1)),
        color=alt.Color(
            f'{f0["col"]}',
            sort=f0["order"],
            scale=f0["colors"]
            ) if len(facets)>=1 else alt.value('red'),
        tooltip=tooltip+([alt.Tooltip('probability:Q',format='.1%',title='category prob.')] if len(facets)>=1 else [])
    )#.add_selection(selection)


    rule = alt.Chart().mark_rule(color='red', strokeDash=[2, 3]).encode(
        y=alt.Y('mv:Q')
    ).transform_joinaggregate(
        mv = f'mean({value_col}):Q',
        groupby=outer_factors
    )

    plot = alt.layer(
        rule,
        line,
        data=tdf,
    )
    return plot

# %% ../nbs/03_plots.ipynb 61
@stk_plot('marimekko', data_format='longform', draws=False, group_sizes=True, args={'separate':'bool'}, n_facets=(2,2))
def marimekko(data, value_col='value', facets=[], val_format='%', width=800, tooltip=[], outer_factors=[], separate=False):
    f0, f1 = facets[0], facets[1]

    #xcol, ycol, ycol_scale = f1["col"], f0["col"], f0["colors"]
    xcol, ycol, ycol_scale = f0["col"], f1["col"], f1["colors"]
     
    data['w'] = data['group_size']*data[value_col]
    data.sort_values([xcol,ycol],ascending=[True,False],inplace=True)

    if separate: # Split and center each ycol group so dynamics can be better tracked for all of them
        ndata = data.groupby(outer_factors+[xcol],observed=False)[[ycol,value_col,'w']].apply(lambda df: pd.DataFrame({ ycol: df[ycol], 'yv': df['w']/df['w'].sum(), 'w': df['w']})).reset_index()
        ndata = ndata.merge(ndata.groupby(outer_factors + [ycol],observed=True)['yv'].max().rename('ym').reset_index(),on=outer_factors + [ycol]).fillna({'ym':0.0})
        ndata = ndata.groupby(outer_factors+[xcol],observed=False)[[ycol,'w','yv','ym']].apply(lambda df: pd.DataFrame({ ycol: df[ycol], 'yv': df['yv'], 'w': df['w'].sum(),
                                                                                                                        'y1': (df['ym'].cumsum()- df['ym']/2 - df['yv']/2)/df['ym'].sum(),
                                                                                                                        'y2': (df['ym'].cumsum()- df['ym']/2 + df['yv']/2)/df['ym'].sum(), })).reset_index()
    else: # Regular marimekko
        ndata = data.groupby(outer_factors+[xcol],observed=False)[[ycol,value_col,'w']].apply(lambda df: pd.DataFrame({ ycol: df[ycol], 'w': df['w'].sum(),
                                                                                                                       'yv': df['w']/df['w'].sum(), 
                                                                                                                       'y2': df['w'].cumsum()/df['w'].sum()})).reset_index()
        ndata['y1'] = ndata['y2']-ndata['yv']
    
    ndata = ndata.groupby(outer_factors+[ycol],observed=False)[[xcol,'yv','y1','y2','w']].apply(lambda df: pd.DataFrame({ xcol: df[xcol], 'xv': df['w']/df['w'].sum(), 'x2': df['w'].cumsum()/df['w'].sum(), 'yv':df['yv'], 'y1':df['y1'], 'y2':df['y2']})).reset_index()
    ndata['x1'] = ndata['x2']-ndata['xv']
    

    #selection = alt.selection_point(fields=[yvar], bind="legend")
    STROKE = 0.25
    plot = alt.Chart(ndata).mark_rect(
            strokeWidth=STROKE,
            stroke="white",
            xOffset=STROKE / 2,
            x2Offset=STROKE / 2,
            yOffset=STROKE / 2,
            y2Offset=STROKE / 2,
        ).encode(
            x=alt.X(
                "x1:Q",
                axis=alt.Axis(
                    zindex=1, format="%", title=[f"{xcol} (% of total)", " "], grid=False
                ),
                scale=alt.Scale(domain=[0, 1]),
            ),
            x2="x2:Q",
            y=alt.Y(
                "y1:Q",
                axis=alt.Axis(
                    zindex=1, format="%", title=f"{ycol} (% of total)", grid=False, labels=not separate
                    ),
                scale=alt.Scale(domain=[0, 1])
            ),
            y2="y2:Q",
            color=alt.Color(
                f"{ycol}:N",
                legend=alt.Legend(title=None, symbolStrokeWidth=0), #title=f"{yvar}"),
                scale=ycol_scale,
            ),
            tooltip=[
                alt.Tooltip("yv:Q", title=f'{ycol} proportion', format='.1%' ),
                alt.Tooltip("xv:Q", title=f'{xcol} proportion', format='.1%' ),
            ]+tooltip[1:],
            #opacity=alt.condition(selection, alt.value(1), alt.value(0.3)),
        )
        #.add_params(selection)
    
    return plot
